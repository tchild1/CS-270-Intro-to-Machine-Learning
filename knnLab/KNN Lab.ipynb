{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVL7_bgmIAPR"
   },
   "source": [
    "# K-Nearest Neighbor Lab\n",
    "Read over the sklearn info on [nearest neighbor learners](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "6ZbYjZZZ_yLV"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 K-Nearest Neighbor (KNN) algorithm\n",
    "\n",
    "### 1.1 (15%) Basic KNN Classification\n",
    "\n",
    "Learn the [Glass data set](https://archive.ics.uci.edu/dataset/42/glass+identification) using [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) with default parameters.\n",
    "- Randomly split your data into train/test.  Anytime we don't tell you specifics (such as what percentage is train vs test) choose your own reasonable values\n",
    "- Give typical train and test set accuracies after running with different random splits\n",
    "- Print the output probabilities for a test set (predict_proba)\n",
    "- Try it with different p values (Minkowskian exponent) and discuss any differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average training score accuacy (train/test split (0.2, 0.8)): 0.7631578947368421\n",
      "average test score accuracy (train/test split (0.2, 0.8)): 0.6534883720930232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average training score accuacy (train/test split (0.3, 0.7)): 0.7657718120805369\n",
      "average test score accuracy (train/test split (0.3, 0.7)): 0.6415384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average training score accuacy (train/test split (0.4, 0.6)): 0.75\n",
      "average test score accuracy (train/test split (0.4, 0.6)): 0.6267441860465116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Learn the glass data\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# fetch dataset \n",
    "glass_identification = fetch_ucirepo(id=42) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = glass_identification.data.features \n",
    "y = glass_identification.data.targets \n",
    "\n",
    "\n",
    "trainTestSplits = [(0.2, 0.8), (0.3, 0.7), (0.4, 0.6)]\n",
    "\n",
    "for split in trainTestSplits:\n",
    "\n",
    "    trainingScores = []\n",
    "    testScores = []\n",
    "    for i in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split[0], train_size=split[1])\n",
    "\n",
    "        classifier = KNeighborsClassifier()\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        testScores.append(classifier.score(X_test, y_test))\n",
    "        trainingScores.append(classifier.score(X_train, y_train))\n",
    "\n",
    "    print(f'average training score accuacy (train/test split {split}):', sum(trainingScores)/len(trainingScores))\n",
    "    print(f'average test score accuracy (train/test split {split}):', sum(testScores)/len(testScores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy:  0.686046511627907\n",
      "training set accuracy:  0.6640625\n",
      "test set output probabilities:  [[1.  0.  0.  0.  0.  0. ]\n",
      " [0.8 0.2 0.  0.  0.  0. ]\n",
      " [0.4 0.2 0.4 0.  0.  0. ]\n",
      " [0.8 0.  0.2 0.  0.  0. ]\n",
      " [0.  1.  0.  0.  0.  0. ]\n",
      " [0.4 0.4 0.2 0.  0.  0. ]\n",
      " [0.  0.8 0.  0.2 0.  0. ]\n",
      " [0.4 0.  0.6 0.  0.  0. ]\n",
      " [1.  0.  0.  0.  0.  0. ]\n",
      " [0.4 0.2 0.4 0.  0.  0. ]\n",
      " [0.  1.  0.  0.  0.  0. ]\n",
      " [1.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  1. ]\n",
      " [0.  0.  0.  1.  0.  0. ]\n",
      " [0.2 0.2 0.4 0.  0.  0.2]\n",
      " [1.  0.  0.  0.  0.  0. ]\n",
      " [0.6 0.2 0.2 0.  0.  0. ]\n",
      " [0.6 0.2 0.2 0.  0.  0. ]\n",
      " [0.2 0.4 0.  0.  0.4 0. ]\n",
      " [0.6 0.4 0.  0.  0.  0. ]\n",
      " [0.2 0.4 0.4 0.  0.  0. ]\n",
      " [0.2 0.8 0.  0.  0.  0. ]\n",
      " [0.2 0.6 0.  0.  0.  0.2]\n",
      " [0.  0.  0.  0.  0.  1. ]\n",
      " [0.2 0.2 0.2 0.  0.2 0.2]\n",
      " [1.  0.  0.  0.  0.  0. ]\n",
      " [1.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.8 0.  0.2 0.  0. ]\n",
      " [0.4 0.6 0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  1. ]\n",
      " [0.6 0.4 0.  0.  0.  0. ]\n",
      " [0.2 0.8 0.  0.  0.  0. ]\n",
      " [0.2 0.4 0.2 0.  0.2 0. ]\n",
      " [0.4 0.2 0.  0.  0.4 0. ]\n",
      " [0.4 0.6 0.  0.  0.  0. ]\n",
      " [0.2 0.8 0.  0.  0.  0. ]\n",
      " [0.4 0.4 0.2 0.  0.  0. ]\n",
      " [0.4 0.6 0.  0.  0.  0. ]\n",
      " [0.6 0.  0.4 0.  0.  0. ]\n",
      " [0.2 0.2 0.  0.6 0.  0. ]\n",
      " [0.4 0.  0.6 0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  1. ]\n",
      " [0.6 0.4 0.  0.  0.  0. ]\n",
      " [0.  0.6 0.  0.4 0.  0. ]\n",
      " [1.  0.  0.  0.  0.  0. ]\n",
      " [0.4 0.6 0.  0.  0.  0. ]\n",
      " [0.  0.6 0.  0.  0.4 0. ]\n",
      " [0.8 0.2 0.  0.  0.  0. ]\n",
      " [0.  1.  0.  0.  0.  0. ]\n",
      " [0.6 0.4 0.  0.  0.  0. ]\n",
      " [0.6 0.2 0.2 0.  0.  0. ]\n",
      " [0.6 0.  0.4 0.  0.  0. ]\n",
      " [0.8 0.  0.2 0.  0.  0. ]\n",
      " [0.  1.  0.  0.  0.  0. ]\n",
      " [0.8 0.  0.2 0.  0.  0. ]\n",
      " [1.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  1. ]\n",
      " [0.  0.  0.  0.  0.  1. ]\n",
      " [0.4 0.4 0.  0.  0.  0.2]\n",
      " [0.2 0.2 0.4 0.  0.  0.2]\n",
      " [0.  1.  0.  0.  0.  0. ]\n",
      " [0.4 0.6 0.  0.  0.  0. ]\n",
      " [0.2 0.8 0.  0.  0.  0. ]\n",
      " [0.6 0.4 0.  0.  0.  0. ]\n",
      " [0.  0.6 0.  0.4 0.  0. ]\n",
      " [0.  1.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  1. ]\n",
      " [0.6 0.2 0.2 0.  0.  0. ]\n",
      " [1.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.8 0.2 0.  0.  0. ]\n",
      " [0.4 0.2 0.4 0.  0.  0. ]\n",
      " [0.6 0.2 0.2 0.  0.  0. ]\n",
      " [0.4 0.6 0.  0.  0.  0. ]\n",
      " [0.2 0.4 0.  0.  0.4 0. ]\n",
      " [0.  0.  0.  0.  0.  1. ]\n",
      " [0.6 0.2 0.2 0.  0.  0. ]\n",
      " [0.8 0.2 0.  0.  0.  0. ]\n",
      " [0.2 0.4 0.2 0.  0.  0.2]\n",
      " [0.8 0.2 0.  0.  0.  0. ]\n",
      " [0.2 0.8 0.  0.  0.  0. ]\n",
      " [0.  1.  0.  0.  0.  0. ]\n",
      " [0.  0.2 0.  0.6 0.  0.2]\n",
      " [0.8 0.  0.2 0.  0.  0. ]\n",
      " [0.8 0.2 0.  0.  0.  0. ]\n",
      " [0.  0.6 0.  0.4 0.  0. ]\n",
      " [0.6 0.2 0.2 0.  0.  0. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Print the output probabilities for a test set (predict_proba)\n",
    "\n",
    "# Learn the glass data\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# fetch dataset \n",
    "glass_identification = fetch_ucirepo(id=42) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = glass_identification.data.features \n",
    "y = glass_identification.data.targets \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split[0], train_size=split[1])\n",
    "\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print('test set accuracy: ', classifier.score(X_test, y_test))\n",
    "print('training set accuracy: ', classifier.score(X_train, y_train)) \n",
    "print('test set output probabilities: ', classifier.predict_proba(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy (p value: 2):  0.627906976744186\n",
      "training set accuracy (p value: 2):  0.75\n",
      "test set accuracy (p value: 3):  0.627906976744186\n",
      "training set accuracy (p value: 3):  0.7265625\n",
      "test set accuracy (p value: 4):  0.6744186046511628\n",
      "training set accuracy (p value: 4):  0.734375\n",
      "test set accuracy (p value: 5):  0.6744186046511628\n",
      "training set accuracy (p value: 5):  0.7265625\n",
      "test set accuracy (p value: 6):  0.6627906976744186\n",
      "training set accuracy (p value: 6):  0.71875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy (p value: 8):  0.6627906976744186\n",
      "training set accuracy (p value: 8):  0.7109375\n",
      "test set accuracy (p value: 10):  0.6511627906976745\n",
      "training set accuracy (p value: 10):  0.7109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\child\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Try it with different p values (Minkowskian exponent) and discuss any differences\n",
    "\n",
    "# Learn the glass data\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# fetch dataset \n",
    "glass_identification = fetch_ucirepo(id=42) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = glass_identification.data.features \n",
    "y = glass_identification.data.targets \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split[0], train_size=split[1])\n",
    "\n",
    "pValues = [2, 3, 4, 5, 6, 8, 10]\n",
    "for pValue in pValues:\n",
    "\n",
    "    classifier = KNeighborsClassifier(p=pValue)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    print(f'test set accuracy (p value: {pValue}): ', classifier.score(X_test, y_test))\n",
    "    print(f'training set accuracy (p value: {pValue}): ', classifier.score(X_train, y_train)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**  \n",
    "| Train/Test Split | Training Accuracy | Test accuracy |\n",
    "| --- | --- | --- |\n",
    "| (0.2, 0.8) | 0.7631578947368421 | 0.6534883720930232 |\n",
    "| (0.3, 0.7) | 0.7657718120805369 | 0.6415384615384616 |\n",
    "| (0.4, 0.6) | 0.75 | 0.6267441860465116 | \n",
    "\n",
    "As you can see above, I started by running the KNeighborsClassifier model on different train/test splits. So, I ran with the splits (0.2, 0.8), (0.3, 0.7), and (0.4, 0.6). Even with these considerably different training/set sets, the accuracies were still very close to each other. All things considered, Training set accuracy was always about 76% and the test set accuracy was always about 64%. Finally, as expeced, the Training accuracy was always slightly higher than the Test accuracy because the training set is the group that the model was trained on, so it had seen it all before.  \n",
    "\n",
    "After experimenting with different training/test splits, I output the probabilities for a test set (with predict_proba). Here are what some of those outputs looked like:  \n",
    "[[0.8 0.2 0.  0.  0.  0. ]  \n",
    " [0.4 0.2 0.4 0.  0.  0. ]  \n",
    " [0.8 0.  0.2 0.  0.  0. ]  \n",
    " [0.  1.  0.  0.  0.  0. ]  \n",
    " [0.4 0.4 0.2 0.  0.  0. ]  \n",
    " [0.  0.8 0.  0.2 0.  0. ]  \n",
    " [0.4 0.  0.6 0.  0.  0. ]  \n",
    " [1.  0.  0.  0.  0.  0. ]  \n",
    " [0.4 0.2 0.4 0.  0.  0. ]  \n",
    " [0.  1.  0.  0.  0.  0. ]  \n",
    " [1.  0.  0.  0.  0.  0. ]  \n",
    " [0.  0.  0.  0.  0.  1. ]  \n",
    " [0.  0.  0.  1.  0.  0. ]  \n",
    " [0.2 0.2 0.4 0.  0.  0.2]  \n",
    " [1.  0.  0.  0.  0.  0. ]  \n",
    " [0.6 0.2 0.2 0.  0.  0. ]  \n",
    " [0.6 0.2 0.2 0.  0.  0. ]  \n",
    " [0.2 0.4 0.  0.  0.4 0. ]  \n",
    " [0.6 0.4 0.  0.  0.  0. ]  \n",
    " [0.2 0.4 0.4 0.  0.  0. ]  \n",
    " [0.2 0.8 0.  0.  0.  0. ]  \n",
    " [0.2 0.6 0.  0.  0.  0.2]  \n",
    "...  \n",
    " [0.8 0.  0.2 0.  0.  0. ]  \n",
    " [0.8 0.2 0.  0.  0.  0. ]  \n",
    " [0.  0.6 0.  0.4 0.  0. ]  \n",
    " [0.6 0.2 0.2 0.  0.  0. ]]    \n",
    "\n",
    "This matrix of values tells us for each instance, the likelyhood of that instance being classified in each output class. So, for example, the row [0.4 0.4 0.2 0.  0.  0. ] means that this instance had a 40% similarity to class 1, 40% similarity to class 2, 20% similarity to class 3, and a negligible similarity to the remaining output classes.  \n",
    "\n",
    "\n",
    "Finally, I experimented with different p values (Minkowskian exponent):  \n",
    "| p value | Training Accuracy | Test accuracy |\n",
    "| --- | --- | --- |\n",
    "| 2 | 0.75 | 0.627906976744186 |\n",
    "| 3 | 0.7265625 | 0.627906976744186 |\n",
    "| 4 | 0.734375 | 0.6744186046511628 |\n",
    "| 5 | 0.7265625 | 0.6744186046511628 | \n",
    "| 6 | 0.71875 | 0.6627906976744186 | \n",
    "| 8 | 0.7109375 | 0.6627906976744186 | \n",
    "| 10 | 0.7109375 | 0.6511627906976745 |  \n",
    "\n",
    "As you can see from the table above, as the p value increased, there was a slight decrease in accuracy for both Training and Test sets. The p value is the Minkowskian exponent, meaning that it factors into the Minkowskian equation and effects the distance calculated betwen points. So it looks like, at least for this dataset, the higher the exponent, the lower the accuracy. Perhaps this is because the more complicated distance equation is unessesary for such a simple dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vWiTdlbR2Xh"
   },
   "source": [
    "## 2 KNN Classification with normalization and distance weighting\n",
    "\n",
    "Use the [magic telescope](https://axon.cs.byu.edu/data/uci_class/MagicTelescope.arff) dataset\n",
    "\n",
    "### 2.1 (5%) - Without Normalization or Distance Weighting\n",
    "- Do random 80/20 train/test splits each time\n",
    "- Run with k=3 and *without* distance weighting and *without* normalization\n",
    "- Show train and test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SSoasDQSKXb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score:  0.883937960042061\n",
      "test score:  0.8120399579390115\n"
     ]
    }
   ],
   "source": [
    "# Learn magic telescope data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# get data\n",
    "magicData = arff.loadarff('magicTelescope.arff')\n",
    "\n",
    "# put data into a data frame\n",
    "magicDataFrame = pd.DataFrame(magicData[0])\n",
    "\n",
    "# define the target\n",
    "y = LabelEncoder().fit_transform(magicDataFrame['class:'])\n",
    "\n",
    "# define the features\n",
    "X = magicDataFrame.drop(columns='class:')\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print('training score: ', classifier.score(X_train, y_train))\n",
    "print('test score: ', classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**  \n",
    "As you can see from the above results, I have run the KNeighborsClassifier with no distance weighting and no normalization. This means that I did not scale down the inputs to be between 0-1. Futher, not using distance weighting means that all distances are weighted 'uniformly'. This is the default parameter, it did not need added. Running my KNeighborsClassifier model on this data I found the following:  \n",
    "\n",
    "training score:  0.883937960042061  \n",
    "test score:  0.8120399579390115  \n",
    "\n",
    "These results look reasonable and expected! The training score is slightly higher than the test score (as usual). However, I do expect these values to be different when I add normalization and distance weighting, see below for those results.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 (10%) With Normalization\n",
    "- Try it with k=3 without distance weighting but *with* normalization of input features.  You may use any reasonable normalization approach (e.g. standard min-max normalization between 0-1, z-transform, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score:  0.9006966351209253\n",
      "test score:  0.8280757097791798\n"
     ]
    }
   ],
   "source": [
    "# Train/Predict with normalization\n",
    "\n",
    "# Learn magic telescope data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# get data\n",
    "magicData = arff.loadarff('magicTelescope.arff')\n",
    "\n",
    "# put data into a data frame\n",
    "magicDataFrame = pd.DataFrame(magicData[0])\n",
    "\n",
    "# define the target\n",
    "y = LabelEncoder().fit_transform(magicDataFrame['class:'])\n",
    "\n",
    "# define the features\n",
    "X = magicDataFrame.drop(columns='class:')\n",
    "\n",
    "X = pd.DataFrame(MinMaxScaler().fit_transform(X), columns=X.columns)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print('training score: ', classifier.score(X_train, y_train))\n",
    "print('test score: ', classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Discuss the results of using normalized data vs. unnormalized data*  \n",
    "\n",
    "**Discussion:**  \n",
    "In the first example, I used unnormalized data with k=3 on the KNeighborsClassifier model. On the second example, I used the exact same data, still with k=3 on the KNeighborsClassifier model.  \n",
    "\n",
    "Unnormalized Data Results:  \n",
    "training score:  0.883937960042061  \n",
    "test score:  0.8120399579390115  \n",
    "\n",
    "Normalized Data Results:  \n",
    "training score:  0.9006966351209253  \n",
    "test score:  0.8280757097791798  \n",
    "\n",
    "Interestingly, comparing these results, I observed a slight increase in both training and test accuracy with the data normalized. I think that I saw this improvement because normalized data prevents outlier data or other large numbers from dominating the model's classification decision. For this reason, it is usually a good idea to normalize all data before training your model on it. So, in conclusion, when using most models (KNeighborsClassifier) included it is wise to normalize your data prior to training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 (10%) With Distance Weighting\n",
    "- Try it with k=3 and with distance weighting *and* normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score:  1.0\n",
      "test score:  0.8343848580441641\n"
     ]
    }
   ],
   "source": [
    "#Train/Precdict with normalization and distance weighting\n",
    "\n",
    "# Learn magic telescope data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# get data\n",
    "magicData = arff.loadarff('magicTelescope.arff')\n",
    "\n",
    "# put data into a data frame\n",
    "magicDataFrame = pd.DataFrame(magicData[0])\n",
    "\n",
    "# define the target\n",
    "y = LabelEncoder().fit_transform(magicDataFrame['class:'])\n",
    "\n",
    "# define the features\n",
    "X = magicDataFrame.drop(columns='class:')\n",
    "\n",
    "# normalize data\n",
    "X = pd.DataFrame(MinMaxScaler().fit_transform(X), columns=X.columns)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print('training score: ', classifier.score(X_train, y_train))\n",
    "print('test score: ', classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison and Discussion:**  \n",
    "In this example, in addition to appying normalization to my data, I also added distance weighting. As you can see from this data, I saw another significant improvement over normalization when adding distance weighting.  \n",
    "\n",
    "Unnormalized Data Results:  \n",
    "training score:  0.883937960042061  \n",
    "test score:  0.8120399579390115  \n",
    "\n",
    "Normalized Data Results:  \n",
    "training score:  0.9006966351209253  \n",
    "test score:  0.8280757097791798  \n",
    "\n",
    "With Distance Weighting and Normalization:  \n",
    "training score:  1.0  \n",
    "test score:  0.8343848580441641  \n",
    "\n",
    "While I observed a small improvement when normalizing the data before training my model on it, I saw another improvement in accuracy when adding distance weighting. Further, while training saw a huge accuracy improvement and test saw a small improvement. I think I observed these improvements because when adding distance weighting the influence of a point is determined by the inverse of its distance. That means, that neighbors that are further away have less of an influence on the output of a class. Not surprisingly, this improved the accuracy of my model because the closest points had the greatest influence on the classification of a new point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 (10%) Different k Values\n",
    "- Using your normalized data with distance weighting, create one graph with classification accuracy on the test set on the y-axis and k values on the x-axis.\n",
    "- Use values of k from 1 to 15.  Use the same train/test split for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate and Graph classification accuracy vs k values\n",
    "\n",
    "# Learn magic telescope data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get data\n",
    "magicData = arff.loadarff('magicTelescope.arff')\n",
    "\n",
    "# put data into a data frame\n",
    "magicDataFrame = pd.DataFrame(magicData[0])\n",
    "\n",
    "# define the target\n",
    "y = LabelEncoder().fit_transform(magicDataFrame['class:'])\n",
    "\n",
    "# define the features\n",
    "X = magicDataFrame.drop(columns='class:')\n",
    "\n",
    "# normalize data\n",
    "X = pd.DataFrame(MinMaxScaler().fit_transform(X), columns=X.columns)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8)\n",
    "\n",
    "\n",
    "allTestSetAccuracies = []\n",
    "for k in range(1, 16):\n",
    "\n",
    "    testSetAccuraciesForK = []\n",
    "    for i in range(10):\n",
    "\n",
    "        classifier = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        testSetAccuraciesForK.append(classifier.score(X_test, y_test))\n",
    "\n",
    "    allTestSetAccuracies.append(sum(testSetAccuraciesForK)/len(testSetAccuraciesForK))\n",
    "\n",
    "\n",
    "plt.plot(range(len(allTestSetAccuracies)), allTestSetAccuracies, marker='o')\n",
    "plt.xlabel('k value')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**  \n",
    "\n",
    "Note, on the above graph I ran 10 iterations at each k value and averaged them to get better results.  \n",
    "\n",
    "Observing the output graph above, you can see that as the k value increased, the test set accuracy generally increased as well, but did plateu a little bit after k=8. You might wonder why there wasn't constant increase, why, for example there are local mins and maxes on this graph. I think that this has to do with the nature of the K nearest neighbor algorithm. Depending on the placement of certain instances and at with certain values of k, you might see a lower accuracy because it is observing a number of instances that are less helpful in contributing to a high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIRG42TgSR4x"
   },
   "source": [
    "## 3 KNN Regression with normalization and distance weighting\n",
    "\n",
    "Use the [sklean KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor) on the [housing price prediction](https://axon.cs.byu.edu/data/uci_regression/housing.arff) problem.  \n",
    "### 3.1 (5%) Ethical Data\n",
    "Note this data set has an example of an inappropriate input feature which we discussed.  State which feature is inappropriate and discuss why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss the innapropriate feature**  \n",
    "\n",
    "The inappropriate input feature is B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town. This feature is inappropriate because it is not right to base house prices on the number of people of a certain race in an area. Further, but incorporating this feature into your model, it will continue to undervalue those areas and make the predudice against these areas worse. Models are only as good as the data we give them, if we feed them data that makes decisions based on the race of people in an area, problems with race will only get worse, so this feature is an unethical one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 (15%) - KNN Regression \n",
    "- Do random 80/20 train/test splits each time\n",
    "- Run with k=3\n",
    "- Print the score (coefficient of determination) and Mean Absolute Error (MAE) for the train and test set for the cases of\n",
    "  - No input normalization and no distance weighting\n",
    "  - Normalization and no distance weighting\n",
    "  - Normalization and distance weighting\n",
    "- Normalize inputs features where needed but do not normalize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KBGUn43ASiXW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.7350975820980463\n",
      "training accuracy:  0.7815179720353461\n",
      "test MAE 3.658496732026144\n",
      "training MAE 2.7386963696369637\n"
     ]
    }
   ],
   "source": [
    "# Learn and experiment with housing price prediction data\n",
    "\n",
    "# Learn magic telescope data\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get data\n",
    "housingData = arff.loadarff('housingPrices.arff')\n",
    "\n",
    "# put data into a data frame\n",
    "housingDataFrame = pd.DataFrame(housingData[0])\n",
    "\n",
    "# define the target\n",
    "y = housingDataFrame['MEDV']\n",
    "\n",
    "# define the features\n",
    "X = housingDataFrame.drop(columns='MEDV')\n",
    "X = X.drop(columns='B')\n",
    "\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8)\n",
    "\n",
    "\n",
    "classifier = KNeighborsRegressor(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print('test accuracy: ', classifier.score(X_test, y_test))\n",
    "print('training accuracy: ', classifier.score(X_train, y_train))\n",
    "print('test MAE', mean_absolute_error(classifier.predict(X_test), y_test))\n",
    "print('training MAE', mean_absolute_error(classifier.predict(X_train), y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.7785898841205592\n",
      "training accuracy:  0.8838977512822767\n",
      "test MAE 2.965686274509804\n",
      "training MAE 2.0628712871287127\n"
     ]
    }
   ],
   "source": [
    "# Learn and experiment with housing price prediction data\n",
    "\n",
    "# Learn magic telescope data\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get data\n",
    "housingData = arff.loadarff('housingPrices.arff')\n",
    "\n",
    "# put data into a data frame\n",
    "housingDataFrame = pd.DataFrame(housingData[0])\n",
    "\n",
    "# define the target\n",
    "y = housingDataFrame['MEDV']\n",
    "\n",
    "# define the features\n",
    "X = housingDataFrame.drop(columns='MEDV')\n",
    "X = X.drop(columns='B')\n",
    "X = pd.DataFrame(MinMaxScaler().fit_transform(X), columns=X.columns)\n",
    "\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8)\n",
    "\n",
    "\n",
    "classifier = KNeighborsRegressor(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print('test accuracy: ', classifier.score(X_test, y_test))\n",
    "print('training accuracy: ', classifier.score(X_train, y_train))\n",
    "print('test MAE', mean_absolute_error(classifier.predict(X_test), y_test))\n",
    "print('training MAE', mean_absolute_error(classifier.predict(X_train), y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.815339758898793\n",
      "training accuracy:  1.0\n",
      "test MAE 2.4924948384436703\n",
      "training MAE 0.0\n"
     ]
    }
   ],
   "source": [
    "# Learn and experiment with housing price prediction data\n",
    "\n",
    "# Learn magic telescope data\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get data\n",
    "housingData = arff.loadarff('housingPrices.arff')\n",
    "\n",
    "# put data into a data frame\n",
    "housingDataFrame = pd.DataFrame(housingData[0])\n",
    "\n",
    "# define the target\n",
    "y = housingDataFrame['MEDV']\n",
    "\n",
    "# define the features\n",
    "X = housingDataFrame.drop(columns='MEDV')\n",
    "X = X.drop(columns='B')\n",
    "X = pd.DataFrame(MinMaxScaler().fit_transform(X), columns=X.columns)\n",
    "\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8)\n",
    "\n",
    "\n",
    "classifier = KNeighborsRegressor(n_neighbors=3, weights='distance')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print('test accuracy: ', classifier.score(X_test, y_test))\n",
    "print('training accuracy: ', classifier.score(X_train, y_train))\n",
    "print('test MAE', mean_absolute_error(classifier.predict(X_test), y_test))\n",
    "print('training MAE', mean_absolute_error(classifier.predict(X_train), y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**  \n",
    "Over the three previous cells, I experimented with:  \n",
    "  - No input normalization and no distance weighting\n",
    "  - Normalization and no distance weighting\n",
    "  - Normalization and distance weighting  \n",
    "\n",
    "With these conditions, I observed the following results in accuracy and MAE:  \n",
    "\n",
    "- No input normalization and no distance weighting:  \n",
    "test accuracy:  0.7350975820980463  \n",
    "training accuracy:  0.7815179720353461  \n",
    "test MAE 3.658496732026144  \n",
    "training MAE 2.7386963696369637    \n",
    "\n",
    "- Normalization and no distance weighting:  \n",
    "test accuracy:  0.7785898841205592  \n",
    "training accuracy:  0.8838977512822767  \n",
    "test MAE 2.965686274509804  \n",
    "training MAE 2.0628712871287127    \n",
    "\n",
    "- Normalization and distance weighting:    \n",
    "test accuracy:  0.815339758898793  \n",
    "training accuracy:  1.0  \n",
    "test MAE 2.4924948384436703  \n",
    "training MAE 0.0  \n",
    "\n",
    "\n",
    "From these results one can see that the test accuracy without weighting and without normalization was 0.7350975820980463, while the training accuracy was 0.7815179720353461. However, once the input data was normalized (scaled from 0-1), the test accuracy increased by almost 5% to 0.7785898841205592 and the training increased to 0.8838977512822767, about 10%. Finally, in addition to normalizing my input features, I weighted the distances. After distance weighting test accuracy saw another 4% increase to 0.815339758898793 and training saw another increase to 1.0. Likewise, there were significant inprovements observed in the MAE.  \n",
    "\n",
    "Looking at the improvements over these results I believe that normalization played a big role. Especially when considering housing prices, there is likely a wide range of values for both inputs and outputs, so normalization played a huge role is ensuring that large numbers, outliers or not, didn't throw off results. Further, I was another improvement when distance weighting was added. Distance weighting will consider how CLOSE an instance is to other instances in the calculation of what the new instance should be labeled. This lends a huge improvement because now rather than just considering the k nearest neighbors, the closest neighbors have the greatest influence. Both normalization and distance weighting played a huge factor in the observed results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 (10%)  Different k Values\n",
    "- Using housing with normalized data and distance weighting, create one graph with MAE on the test set on the y-axis and k values on the x-axis\n",
    "- Use values of k from 1 to 15.  Use the same train/test split for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Learn and graph for different k values\n",
    "\n",
    "# Learn and experiment with housing price prediction data\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get data\n",
    "housingData = arff.loadarff('housingPrices.arff')\n",
    "\n",
    "# put data into a data frame\n",
    "housingDataFrame = pd.DataFrame(housingData[0])\n",
    "\n",
    "# define the target\n",
    "y = housingDataFrame['MEDV']\n",
    "\n",
    "# define the features\n",
    "X = housingDataFrame.drop(columns='MEDV')\n",
    "X = X.drop(columns='B')\n",
    "X = pd.DataFrame(MinMaxScaler().fit_transform(X), columns=X.columns)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8)\n",
    "\n",
    "\n",
    "\n",
    "allMAE = []\n",
    "for k in range(1, 16):\n",
    "\n",
    "    MAEforK = []\n",
    "    for iteration in range(10):\n",
    "\n",
    "        classifier = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        MAEforK.append(mean_absolute_error(classifier.predict(X_test), y_test))\n",
    "\n",
    "    allMAE.append(sum(MAEforK)/len(MAEforK))\n",
    "\n",
    "\n",
    "plt.plot(range(len(allMAE)), allMAE, marker='o')\n",
    "plt.xlabel('k value')\n",
    "plt.ylabel('MAE')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**  \n",
    "\n",
    "This revealed interesting results. Above, I ran the KNeighborsRegressor with k values from 1-15, each 10 times to average results. Inserestingly, as you can see from the chart above, with a k value of 0, the MAE was moderately high, but then minimized at a k value of 2. Then, after k=2, MAE steadily increased all the way to 15.  \n",
    "\n",
    "I find these results really interesting. I expect that I observed what I did because the k value tells the new instance how many surrounding instances to observe. With a k value of zero, MAE was moderately high becaue it couldn't get any context from surrounding instances. At k=2, the new instance was able to get considerable contribution from the closest instances. However, after k=2 we saw huge increases in MAE becauese getting information from more than 2 instances likely reached too far and the data gathered from these new instances didn't help contribute anything.  \n",
    "\n",
    "From this data we can see that there is a sweet spot for the k value, a bigger value can provide noise to the determination of a new instances value, but 0 doesn't give any information at all. In this case, that sweet spot was hit at k=2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. (20%) KNN with nominal and real data\n",
    "\n",
    "- Use the [lymph dataset](https://axon.cs.byu.edu/data/uci_class/lymph.arff)\n",
    "- Use a 80/20 split of the data for the training/test set\n",
    "- This dataset has both continuous and nominal attributes \n",
    "- Implement a distance metric which uses Euclidean distance for continuous features and 0/1 distance for nominal. Hints:\n",
    "    - Write your own distance function (e.g. mydist) and use clf = KNeighborsClassifier(metric=mydist)\n",
    "    - Change the nominal features in the data set to integer values since KNeighborsClassifier expects numeric features. I used Label_Encoder on the nominal features.\n",
    "    - Keep a list of which features are nominal which mydist can use to decide which distance measure to use\n",
    "    - There was an occasional bug in SK version 1.3.0 (\"Flags object has no attribute 'c_contiguous'\") that went away when I upgraded to the lastest SK version 1.3.1 \n",
    "- Use your own choice for k and other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# Train/Predict lymph with your own distance metric\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# get data\n",
    "lymphData = arff.loadarff('lymph.arff')\n",
    "\n",
    "# put data into a data frame\n",
    "lymphDataFrame = pd.DataFrame(lymphData[0])\n",
    "\n",
    "# define the target\n",
    "y = LabelEncoder().fit_transform(lymphDataFrame['class'])\n",
    "\n",
    "# define the features\n",
    "X = lymphDataFrame.drop(columns='class')\n",
    "\n",
    "# transform data\n",
    "X['lymphatics'] = LabelEncoder().fit_transform(X['lymphatics'])\n",
    "X['block_of_affere'] = LabelEncoder().fit_transform(X['block_of_affere'])\n",
    "X['bl_of_lymph_c'] = LabelEncoder().fit_transform(X['bl_of_lymph_c'])\n",
    "X['bl_of_lymph_s'] = LabelEncoder().fit_transform(X['bl_of_lymph_s'])\n",
    "X['by_pass'] = LabelEncoder().fit_transform(X['by_pass'])\n",
    "X['extravasates'] = LabelEncoder().fit_transform(X['extravasates'])\n",
    "X['regeneration_of'] = LabelEncoder().fit_transform(X['regeneration_of'])\n",
    "X['early_uptake_in'] = LabelEncoder().fit_transform(X['early_uptake_in'])\n",
    "X['changes_in_lym'] = LabelEncoder().fit_transform(X['changes_in_lym'])\n",
    "X['defect_in_node'] = LabelEncoder().fit_transform(X['defect_in_node'])\n",
    "X['changes_in_node'] = LabelEncoder().fit_transform(X['changes_in_node'])\n",
    "X['changes_in_stru'] = LabelEncoder().fit_transform(X['changes_in_stru'])\n",
    "X['special_forms'] = LabelEncoder().fit_transform(X['special_forms'])\n",
    "X['dislocation_of'] = LabelEncoder().fit_transform(X['dislocation_of'])\n",
    "X['exclusion_of_no'] = LabelEncoder().fit_transform(X['exclusion_of_no'])\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8)\n",
    "\n",
    "\n",
    "def distance(array1, array2):\n",
    "    totalDistance = 0\n",
    "\n",
    "    for index in range(len(array1)):\n",
    "\n",
    "        # euclidian distance for these attributes\n",
    "        if index in { 8, 9, 17 }:\n",
    "            totalDistance += math.sqrt((array1[index] - array2[index])**2) \n",
    "        else:\n",
    "            # 1/0 for the rest of attributes\n",
    "            if array1[index] == array2[index]:\n",
    "                totalDistance += 0\n",
    "            else:\n",
    "                totalDistance += 1\n",
    "\n",
    "    return totalDistance\n",
    "\n",
    "\n",
    "classifier = KNeighborsClassifier(metric=distance, n_neighbors=2)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(classifier.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**  \n",
    "\n",
    "As you can see from the above cell, I trained my data on the lymph dataset provided. First, with a series of LabelEncoder().fit_transform(), I encoded all nominal values to be integers. Then, as directed, I wrote a ditance function designed to use euclidean distance between continuous features and 1/0 distance between nominal features. You can see this distance function implemented with distane() in the above cell.  \n",
    "\n",
    "This was a really unique implementation because it required me to read online how to implemente a distance function with KNeighborsClassifier. Once I saw that it needed to accept two arrays, implemented my function to measure the distance between each corresponding index, where 1/0 is done for every index except a set of 3 continuous data instances where the euclidean distance measure was used (math.sqrt((array1[index] - array2[index])**2)).  \n",
    "\n",
    "Finally, looking directly at the results of my experiments with KNeighborsClassifier and implementing my own distance function, I found that I was able to get a decent accuracy on my test set of 80%. For comparison, without implementing my distance function (just using 'pass') I was getting an accuracy of about 40%. So as you can see, implementing this distance function roughly doubled the accuracy of the classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (Optional 15% extra credit) Code up your own KNN Learner \n",
    "Below is a scaffold you could use if you want. Requirements for this task:\n",
    "- Your model should support the methods shown in the example scaffold below\n",
    "- Use Euclidean distance to decide closest neighbors\n",
    "- Implement both the classification and regression versions\n",
    "- Include optional distance weighting for both algorithms\n",
    "- Run your algorithm on the magic telescope and housing data sets above and discuss and compare your results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Discussion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class KNNClassifier(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self, columntype=[], weight_type='inverse_distance'): ## add parameters here\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            columntype for each column tells you if continues[real] or if nominal[categoritcal].\n",
    "            weight_type: inverse_distance voting or if non distance weighting. Options = [\"no_weight\",\"inverse_distance\"]\n",
    "        \"\"\"\n",
    "        self.columntype = columntype #Note This won't be needed until part 5\n",
    "        self.weight_type = weight_type\n",
    "\n",
    "    def fit(self, data, labels):\n",
    "        \"\"\" Fit the data; run the algorithm (for this lab really just saves the data :D)\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "            y (array-like): A 2D numpy array with the training targets\n",
    "        Returns:\n",
    "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def predict(self, data):\n",
    "        \"\"\" Predict all classes for a dataset X\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "        Returns:\n",
    "            array, shape (n_samples,)\n",
    "                Predicted target values per element in X.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    #Returns the Mean score given input data and labels\n",
    "    def score(self, X, y):\n",
    "        \"\"\" Return accuracy of model on a given dataset. Must implement own score function.\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with data, excluding targets\n",
    "            y (array-like): A 2D numpy array with targets\n",
    "        Returns:\n",
    "            score : float\n",
    "                Mean accuracy of self.predict(X) wrt. y.\n",
    "        \"\"\"\n",
    "        return 0"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab 1 - perceptron",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
